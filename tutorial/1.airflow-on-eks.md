```
export CLUSTER_NAME="training-on-eks"
```


### 1. IAM 및 Namespace 준비 ###
먼저 Airflow가 설치될 공간과 S3 로그 저장 등을 위한 IAM 역할을 생성합니다. (eksctl 사용)
```
kubectl create namespace airflow

# S3 접근 권한을 가진 ServiceAccount 생성 (IRSA)
eksctl create iamserviceaccount \
  --name airflow-sa \
  --namespace airflow \
  --cluster ${CLUSTER_NAME}\
  --role-name AirflowEKSRole \
  --attach-policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess \
  --approve
```

### 2. Git 접속 정보(SSH Key) 설정 ###
Airflow가 Git에 접속할 수 있도록 SSH Key를 쿠버네티스 시크릿으로 등록해야 한다.

![](https://github.com/gnosia93/mlops-on-eks/blob/main/images/github-deploy-key.png)
```
# 1. SSH 키 생성 (이미 있다면 건너뜀)
ssh-keygen -t rsa -b 4096 -f ./airflow-git-key

# 2. 생성된 public key(.pub)를 GitHub/GitLab의 'Deploy Keys'에 등록

# 3. Private Key를 쿠버네티스 Secret으로 생성
kubectl create secret generic airflow-git-ssh-secret \
  --from-file=gitSshKey=./airflow-git-key \
  -n airflow

kubectl get secret airflow-git-ssh-secret -n airflow -o yaml
```

### 3. SC 생성 ###
```
cat <<EOF > gp3-sc.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: gp3
  annotations:
    # 이 클래스를 클러스터의 기본 스토리지 클래스로 설정합니다.
    storageclass.kubernetes.io/is-default-class: "true"
provisioner: ebs.csi.aws.com
parameters:
  type: gp3
  fsType: ext4
reclaimPolicy: Delete
volumeBindingMode: WaitForFirstConsumer
allowVolumeExpansion: true
EOF
```
```
kubectl apply -f gp3-sc.yaml

kubectl get sc
```
[결과]
```
NAME            PROVISIONER             RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
gp2             kubernetes.io/aws-ebs   Delete          WaitForFirstConsumer   false                  6d3h
gp3 (default)   ebs.csi.aws.com         Delete          WaitForFirstConsumer   true                   3s
```

### 4. airflow 설치 ###
Git-Sync 활성화와 외부 서비스 연결을 포함한 설정 파일이다. 깃허브 레포지토리의 경우 ssh 주소를 넣어야 한다. 
```
cat <<'EOF' > values.yaml
executor: "KubernetesExecutor"

serviceAccount:
  create: false
  name: "airflow-sa"

postgresql:
  enabled: true
  image:
    repository: bitnamilegacy/postgresql
    tag: 16.1.0-debian-11-r15

# Git-Sync 설정 (S3 대신 Git 리포지토리에서 DAG 로드)
dags:
  gitSync:
    enabled: true
    repo: "git@github.com:gnosia93/mlops-on-eks.git"             # SSH 주소
    branch: "main"
    rev: "HEAD"
    depth: 1
    wait: 60  # 60초마다 동기화 체크
    subPath: "dags"                                              # 리포지토리 내 DAG 파일이 있는 특정 폴더 경로
    sshKeySecret: "airflow-git-ssh-secret"                       # 2단계에서 만든 시크릿 이름
EOF
```

airflow 를 설치합니다. 
```
helm repo add apache-airflow https://airflow.apache.org
helm repo update
helm install airflow apache-airflow/airflow --namespace airflow \
  --values values.yaml
```

* 업그레이드 하는 경우
```
helm upgrade --install airflow apache-airflow/airflow --namespace airflow \
  --values values.yaml
```


#### pvc ####
```
# 2. PersistentVolumeClaim (PVC) 생성
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: data-airflow-postgresql-0
  namespace: airflow
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 20Gi            # 원하는 용량
  storageClassName: gp3        # 위에서 정의한 gp3 사용
```

### 5. airflow 설치 확인 ###
```
kubectl get pods -n airflow
```
[결과]
```
NAME                                     READY   STATUS    RESTARTS   AGE
airflow-api-server-7df486c875-rwgl2      1/1     Running   0          2m55s
airflow-dag-processor-57cbc555cf-64bkl   3/3     Running   0          2m55s
airflow-postgresql-0                     1/1     Running   0          2m55s
airflow-scheduler-594bdd5784-n9f4w       2/2     Running   0          2m55s
airflow-statsd-697864869f-mlrzv          1/1     Running   0          2m55s
airflow-triggerer-6d5797d58-hdgvq        3/3     Running   0          2m55s
```

### 6. airflow 접속 ###
```
kubectl patch svc airflow-api-server -n airflow \
  -p '{"spec": {"type": "LoadBalancer", "loadBalancerSourceRanges": ["122.36.213.114/32"]}}'
```
![](https://github.com/gnosia93/mlops-on-eks/blob/main/images/airflow-1.png)
아아이디와 패스워드는 admin/admin 이다.
![](https://github.com/gnosia93/mlops-on-eks/blob/main/images/airflow-2.png)



4. Git-Sync 작동 확인
로그인 후 메인 화면에 gnosia93/mlops-on-eks 리포지토리의 dags 폴더에 들어있는 DAG 목록이 보인다면, Git-Sync 설정까지 완벽하게 작동하고 있는 것입니다.

## 레퍼런스 ##
* https://airflow.apache.org/docs/helm-chart/stable/quick-start.html#
## TODO : LLM 파이프라인 개발 워크플로우 ##
* 코드 수정: 로컬 IDE에서 DAG 파일(예: llm_finetune_dag.py)을 작성합니다.
* Git Push: git push origin main으로 코드를 올립니다.
* 자동 반영: EKS에 떠 있는 Airflow Git-Sync 컨테이너가 60초 이내에 새 코드를 감지하여 웹 UI에 표시합니다.
* 학습 실행: DAG가 실행되면 KubernetesPodOperator가 GPU 노드에 학습용 Pod를 띄워 파인튜닝을 시작합니다.

